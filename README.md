# learn-ai
Learn AI is an initiative where i will be sharing my learning on Generative AI.

# **_With Generative AI ‚ö°, NOW DATA IS THE NEW OIL üõ¢Ô∏èüõ¢Ô∏èüõ¢Ô∏è_**

## First understand Spectrum of AI:


|Aspect|Generative AI                |Predictive AI|
|------|-----------------------------|-------------|
|Definition|AI systems that generate entirely new data, such as images, audio, or text, based on patterns and relationships in existing data.|AI systems that make predictions or classifications based on patterns and relationships in existing data.|
|Output|Unique and original data that has never been seen before.|Predictions or classifications based on existing data.|
|Training Data|Needs large amounts of training data to learn the patterns and relationships in the data.|Needs large amounts of labeled data to learn the patterns and relationships in the data.|
|Use Cases|Art and music generation, text and image synthesis, chatbots, and language translation.|Fraud detection, customer segmentation, stock price prediction, and demand forecasting.|
|Examples|Generative Adversarial Networks (GANs) for image and video generation, Variational Autoencoders (VAEs) for text generation, and Deep Dream for image synthesis.|Logistic Regression for binary classification, Support Vector Machines (SVMs) for image recognition, and Random Forests for stock price prediction.|


# Generative AI has opened ocean of opportunities
 - Conversational Human like patterns
 - Process Complex Data and generate new unseen data
 - Improving productivity and efficiency 

# What is language model?

![Language model](/assets/language-model.png "Language model")



# Important Jargons for Generative AI

|Jargon|Definition                   |Why We Use Them|Examples                                     |
|------|-----------------------------|---------------|---------------------------------------------|
|Large Language Model (LLM)|A type of language model that is trained on massive amounts of text data to generate human-like responses to natural language queries.|To generate more human-like responses in natural language processing applications.|GPT-3, BERT, Transformer-XL                  |
|Models|In machine learning, a model refers to an algorithm that has been trained on data to make predictions or decisions.|To make predictions or decisions based on data.|Linear Regression, Random Forest, Neural Networks|
|Prompt Engineering|The process of designing and refining natural language prompts to elicit desired responses from a language model.|To improve the performance of language models in natural language processing applications.|Few-Shot Prompting, PET                      |
|Embeddings|A way of representing words or phrases as vectors in a high-dimensional space, often used in natural language processing tasks such as sentiment analysis or language translation.|To capture the meaning and context of words or phrases in natural language processing applications.|Word2Vec, GloVe, BERT embeddings             |
|Vector Database|A database that stores vector representations of data, often used for similarity searches or recommendation systems.|To enable fast and efficient similarity searches or recommendations based on vector representations of data.|Apache Solr, Elasticsearch, Annoy            |
|Fact Checked|The process of verifying the accuracy of information, often used in natural language processing tasks such as question answering or language generation.|To ensure the accuracy and credibility of information generated by language models.|Google's Fact Check, Full Fact's Live Fact Checking|
|Recommendation Engine|A type of AI system that uses machine learning algorithms to recommend products, services, or content to users based on their past behavior or preferences.|To personalize recommendations for users and improve engagement and revenue.|Netflix's recommendation engine, Amazon's personalized product recommendations|
|Transfer Learning|A machine learning technique where a model is pre-trained on a large dataset and then fine-tuned on a smaller, related dataset to improve performance.|To improve the performance of machine learning models in cases where labeled data is limited or expensive.|OpenAI's GPT models, Google's BERT           |
|Zero-Shot Learning|A type of machine learning where a model is able to perform a task without any training data, by using its knowledge of related tasks.|To enable machine learning models to generalize to new tasks without the need for extensive training data.|GPT-3's zero-shot learning capabilities      |
|Multi-Modal Learning|A type of machine learning that combines information from multiple sources, such as text, images, and audio, to improve performance on a given task.|To improve the performance of machine learning models in cases where multiple modalities of data are available.|Google's SoundNet, Facebook's Multi-Modal Framework|
|AutoML|Short for "Automated Machine Learning," AutoML refers to the use of automated tools and algorithms to optimize the process of building and deploying machine learning models.|To automate the process of building and deploying machine learning models, making it faster and more efficient.|Google's AutoML, H2O.ai's Driverless AI      |
|Explainability|The ability to understand and interpret the decisions made by a machine learning model, particularly in high-stakes applications such as healthcare or finance.|To increase trust and transparency in machine learning models and enable better decision-making.|LIME, SHAP, IBM's AI Fairness 360            |
|Federated Learning|A type of machine learning where multiple devices or servers collaborate to train a model|               |                                             |


# Step by step Learning Roadmap for Generative AI(Not exhaustive)

|Step|Description                  |
|----|-----------------------------|
|1.  |Learn the basics of machine learning, including supervised and unsupervised learning, as well as neural networks.|
|2.  |Familiarize yourself with deep learning frameworks such as TensorFlow and PyTorch.|
|3.  |Understand Language Models with a Learned Prompt (LLMs), such as GPT-3, which use a large neural network to generate human-like text based on a provided prompt.|
|4.  |Learn about Embeddings, which are representations of words or pieces of text as vectors in a high-dimensional space. Word2Vec is a popular technique for generating word embeddings.|
|5.  |Study Prompt Engineering, which is the process of designing and optimizing prompts for language models to generate desired outputs.|
|6.  |Explore Generative Adversarial Networks (GANs), which are one of the most popular techniques for generative AI. Learn how GANs work, their architecture, and how to implement them using TensorFlow or PyTorch.|
|7.  |Understand Variational Autoencoders (VAEs), which are another popular technique for generative AI, based on the idea of encoding data into a low-dimensional space and then decoding it to generate new data. Learn how VAEs work and how to implement them using TensorFlow or PyTorch.|
|8.  |Experiment with other generative AI techniques, such as Generative Adversarial Imitation Learning (GAIL), Generative Flow, and Auto-regressive models.|
|9.  |Participate in Kaggle competitions related to generative AI to apply your skills and learn from other professionals.|
|10. |Read research papers from top conferences such as NeurIPS, ICML, and ICLR to stay up-to-date with the latest developments in generative AI.|
|11. |Practice implementing different generative AI techniques on different datasets, experiment with hyperparameters, and fine-tune your models to become more proficient in Generative AI.|

# Tools for beginners to start exploring Generative AI
|Tool Name   |Description                                                                                                                                                                                                                                                           |Use Case                              |Example                                                                                                    |Website Link                           |
|------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------|-----------------------------------------------------------------------------------------------------------|---------------------------------------|
|Hugging Face|An open-source library that provides state-of-the-art pre-trained models for natural language processing (NLP), including machine translation, sentiment analysis, and question-answering. It also offers tools for fine-tuning and training custom models.           |NLP, Chatbots                         |Creating a chatbot for customer service using Hugging Face's pre-trained conversational AI model.          |[Hugging Face](https://huggingface.co/)|
|GPT-3       |A state-of-the-art language model developed by OpenAI that uses deep learning techniques to generate human-like text based on a provided prompt. It has a wide range of applications, including language translation, chatbots, and content generation.               |Content Generation                    |Generating product descriptions for an e-commerce website using GPT-3.                                     |[OpenAI GPT-3](https://openai.com/gpt-3/)|
|Langchain   |A web-based platform that allows users to create custom language models for generative purposes, using a combination of machine learning and human curation. It can be used to build generative chatbots, product descriptions, and other types of text-based content.|Text Generation, Chatbots             |Developing a generative chatbot for a travel company using Langchain's platform.                           |[Langchain](https://langchain.ai/)     |
|Anthropic   |A startup that aims to build AI systems that are aligned with human values and objectives. They offer tools and frameworks for designing and training ethical AI models, as well as consulting services for companies looking to implement AI responsibly.            |Ethics, Responsible AI                |Consulting with a company to help them develop an ethical AI policy using Anthropic's tools and frameworks.|[Anthropic](https://www.anthropic.com/)|
|Ai21.ai     |A platform that offers a range of AI tools and services, including natural language processing (NLP), image recognition, and generative AI models. Their flagship product is a language model that can generate text based on a provided prompt, similar to GPT-3.    |Content Generation, Text Summarization|Generating news article summaries using Ai21's language model.                                             |[Ai21.ai](https://www.ai21.com/)       |
|Bard        |An AI-powered writing assistant that can generate suggestions for improving written content, including grammar and style. It can also provide feedback on readability and tone.                                                                                       |Writing Assistance                    |Improving the readability and clarity of a blog post using Bard's suggestions.                             |[Bard](https://bard.co/)               |
|Dall-E      |A generative model developed by OpenAI that can generate images from textual descriptions. It has a wide range of applications, including art and design.                                                                                                             |Image Generation                      |Creating custom illustrations for a children's book using Dall-E's image generation capabilities.          |[OpenAI Dall-E](https://openai.com/dall-e/)|



# Building Custom Chatbot using Javascript
|Step 1|Setting up the Langchain Backend(Javascript)|
|------|--------------------------------|
|a.	Setup Backend Langchain repository by following instructions [Langchain Javascript Framework](https://js.langchain.com/docs/)                               |
|b.	Choose the appropriate language model for your chatbot based on the type of conversations you want it to have. Example- I used gpt-3.5-turbo |                                |
|3.     Generate the OpenAI Key from [OpenAI Developer Platform](https://platform.openai.com/account/api-keys) |                                |
|3.	Train the model on a dataset of example conversations to improve its accuracy and performance|                                |
|4.	Test the model using Langchain's built-in chatbot interface to ensure it's working as expected.|                                |
|5.	Can also use [Langchain starter template](https://github.com/domeccleston/langchain-ts-starter). Need Node version: 18+|                                |
|Step 2| Creating the React Frontend    |
|1.	Set up a new React project using a tool like Create React App.|                                |
|2.	Add any necessary dependencies, such as Axios/React Query for making HTTP requests.|                                |
|3.	Create a new component for your chatbot interface.|                                |
|4.	Add a form input for the user to enter their messages and a container to display the chat history.|                                |
|5.	Set up an event listener to handle form submissions and send user messages to the Langchain API.|                                |
|6.	Use Axios to make a POST request to the Langchain API with the user's message and your API key.|                                |
|7.	Handle the API response by appending the chat history container with the bot's response.|                                |
|8.	Add any necessary styling to the chatbot interface to improve the user experience.|                                |
|Step 3| Deploying the Chatbot          |
|1.	Deploy your Langchain backend to a server, such as Heroku, that can handle API requests.|                                |
|2.	Update your React frontend to use the URL of your deployed backend instead of the local API endpoint.|                                |
|3.	Deploy your React frontend to a static hosting service, such as Netlify or Vercel. |  


# Concerns about Generative AI

|Concern     |Why it's a concern                                                                                                                                                                                                                                                    |How AI companies are addressing it    |
|------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------|
|Bias and Fairness|Generative AI models may perpetuate and amplify biases present in the training data, leading to unfair or discriminatory outcomes.                                                                                                                                    |Companies are implementing techniques such as data augmentation, fairness constraints, and bias detection and mitigation to reduce bias and increase fairness in their models. For example, OpenAI has created a toolkit for measuring and mitigating bias in language models.|
|Safety and Security|Generative AI models can be used for malicious purposes, such as generating convincing fake media or phishing attacks.                                                                                                                                                |Companies are implementing safeguards such as model monitoring, access controls, and ethical guidelines to prevent misuse of their models. For example, OpenAI has developed a policy of not releasing its most powerful language models to the public, and Google's Project Maven restricts the use of its AI tools in certain applications.|
|Explainability and Transparency|Generative AI models can be difficult to interpret or explain, making it hard to understand how they arrive at their outputs or detect errors.                                                                                                                        |Companies are working on methods such as interpretability frameworks, explainability algorithms, and visualization tools to make their models more transparent and understandable. For example, Google's TCAV (Testing with Concept Activation Vectors) provides a way to examine how specific concepts influence a model's outputs.|
|Scalability and Efficiency|Generative AI models can be computationally intensive and difficult to scale to large datasets or real-time applications.                                                                                                                                             |Companies are exploring techniques such as model distillation, pruning, and optimization to reduce the size and complexity of their models, as well as distributed computing and hardware acceleration to improve performance. For example, OpenAI's GPT-3 model is over 100x larger than its predecessor GPT-2, but uses a combination of pruning and distillation to reduce its computational cost.|
|Ethical and Societal Impacts|Generative AI models may have unintended consequences for society or raise ethical questions about their use.                                                                                                                                                         |Companies are engaging in ethical discussions and developing policies and guidelines to address these concerns. For example, Microsoft's AI principles include a commitment to designing AI systems that are transparent, accountable, and respectful of human rights.|


# Must read articles for Frontend Engineers
 - [How chatgpt generates typewriting effect](https://levelup.gitconnected.com/discovering-the-magic-of-chatgpts-typewriter-reply-animation-b2a751db784a)


# Facts
- 70% of the content on the page is generated by gpt3.5 model